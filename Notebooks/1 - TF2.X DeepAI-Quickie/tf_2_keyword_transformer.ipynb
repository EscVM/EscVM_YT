{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "advisory-marsh",
   "metadata": {},
   "source": [
    "# Keyword Transformer (KWT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-transmission",
   "metadata": {},
   "source": [
    "<img src=\"media/keyword_transformer/kwt.png\" alt=\"kwt\" width=\"500\"/>\n",
    "\n",
    "https://arxiv.org/pdf/2104.00769v2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-exhaust",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T08:42:39.864190Z",
     "start_time": "2021-05-16T08:42:39.733335Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-conducting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:20:07.595801Z",
     "start_time": "2021-05-16T09:20:06.450389Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n",
    "from utils import mel_features\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Set seed for experiment reproducibility\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-penalty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:20:16.025165Z",
     "start_time": "2021-05-16T09:20:15.962064Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-rings",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:20:19.846057Z",
     "start_time": "2021-05-16T09:20:19.843436Z"
    }
   },
   "outputs": [],
   "source": [
    "# set some paths and variables\n",
    "data_dir = pathlib.Path('/home/vitto/tensorflow_datasets/speech_commands_v2') # change your path accordingly\n",
    "\n",
    "labels = ['house', 'tree', 'dog','nine', 'sheila', 'four','seven','backward','wow','stop','eight','on',\n",
    " 'down','bed','zero','off','six','one','five','two','marvin','forward','up','right','three','cat', 'learn',\n",
    " 'bird','yes','no','left', 'follow', 'go', 'happy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-logan",
   "metadata": {},
   "source": [
    "# Import the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-renaissance",
   "metadata": {},
   "source": [
    "Dowload the dataset with 'wget' and copying the download link from ----> http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-orientation",
   "metadata": {},
   "source": [
    "TensorFlow Speech Command dataset is a set of one-second .wav audio files, each containing a single spoken English word. These words are from a small set of commands, and are spoken by a variety of different speakers. 20 of the words are core words, while 10 words are auxiliary words that could act as tests for algorithms in ignoring speeches that do not contain triggers. Included along with the 30 words is a collection of background noise audio files. The dataset was originally designed for limited vocabulary speech recognition tasks. The audio clips were originally collected by Google, and recorded by volunteers in uncontrolled locations around the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-tracker",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:20:40.648766Z",
     "start_time": "2021-05-16T09:20:40.644221Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir.joinpath('README.md').open('r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-remove",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:20:41.462762Z",
     "start_time": "2021-05-16T09:20:41.329366Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "print('Number of total examples:', num_samples)\n",
    "print('Number of examples per label (average):',\n",
    "      len(tf.io.gfile.listdir(str(data_dir/labels[0]))))\n",
    "print('Example file tensor:', filenames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-touch",
   "metadata": {},
   "source": [
    "## Play random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-blake",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:20:42.647047Z",
     "start_time": "2021-05-16T09:20:42.644829Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_audio(audio_binary):                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "    audio, s_rate = tf.audio.decode_wav(audio_binary)\n",
    "    return tf.squeeze(audio, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-niagara",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:20:42.996061Z",
     "start_time": "2021-05-16T09:20:42.993266Z"
    }
   },
   "outputs": [],
   "source": [
    "def play_random(folder, n=10):\n",
    "    files = os.listdir(data_dir.joinpath(folder))\n",
    "    ch = np.random.randint(0, len(files), n)\n",
    "    for i in ch:\n",
    "        audio_binary = tf.io.read_file(data_dir.joinpath(folder, files[i]).as_posix())  # binary\n",
    "        waveform = decode_audio(audio_binary) # decoded\n",
    "        display.display(display.Audio(waveform, rate=16000))                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-access",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:20:43.796588Z",
     "start_time": "2021-05-16T09:20:43.781063Z"
    }
   },
   "outputs": [],
   "source": [
    "play_random('zero')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-obligation",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-covering",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:20:47.857078Z",
     "start_time": "2021-05-16T09:20:47.853642Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2]\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    audio_binary = tf.io.read_file(file_path)  # binary\n",
    "    waveform = decode_audio(audio_binary) # decoded\n",
    "    return waveform, label\n",
    "\n",
    "def import_dataset(file_paths):\n",
    "    waveforms = []\n",
    "    labels = []\n",
    "    for file_path in tqdm(file_paths):\n",
    "        waveform, label = get_waveform_and_label(file_path)\n",
    "        waveforms.append(waveform)\n",
    "        labels.append(label)\n",
    "    return np.array(waveforms), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-scientist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:23:30.539197Z",
     "start_time": "2021-05-16T09:20:47.939367Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = import_dataset(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-nicholas",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:23:30.593743Z",
     "start_time": "2021-05-16T09:23:30.591795Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-proxy",
   "metadata": {},
   "source": [
    "## Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-interaction",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:23:52.931854Z",
     "start_time": "2021-05-16T09:23:52.383939Z"
    }
   },
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 3\n",
    "n = rows*cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 12))\n",
    "for i, (audio, label) in enumerate(zip(X[:n], y[:n])):\n",
    "    r = i // cols\n",
    "    c = i % cols\n",
    "    ax = axes[r][c]\n",
    "    ax.plot(audio.numpy())\n",
    "    label = label.numpy().decode()\n",
    "    ax.set_title(label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-peoples",
   "metadata": {},
   "source": [
    "# Prepare the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-coordinator",
   "metadata": {},
   "source": [
    "## Extract spectrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-maria",
   "metadata": {},
   "source": [
    "You'll convert the waveform into a spectrogram, which shows frequency changes over time and can be represented as a 2D image. This can be done by applying the short-time Fourier transform (STFT) to convert the audio into the time-frequency domain.\n",
    "\n",
    "A Fourier transform (tf.signal.fft) converts a signal to its component frequencies, but loses all time information. The STFT (tf.signal.stft) splits the signal into windows of time and runs a Fourier transform on each window, preserving some time information, and returning a 2D tensor that you can run standard convolutions on.\n",
    "\n",
    "STFT produces an array of complex numbers representing magnitude and phase. However, you'll only need the magnitude for this tutorial, which can be derived by applying tf.abs on the output of tf.signal.stft.\n",
    "\n",
    "Choose frame_length and frame_step parameters such that the generated spectrogram \"image\" is almost square. For more information on STFT parameters choice, you can refer to this video on audio signal processing.\n",
    "\n",
    "You also want the waveforms to have the same length, so that when you convert it to a spectrogram image, the results will have similar dimensions. This can be done by simply zero padding the audio clips that are shorter than one second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-russia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:24:00.620600Z",
     "start_time": "2021-05-16T09:24:00.617455Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(waveform):\n",
    "    # Padding for files with less than 16000 samples\n",
    "    zero_padding = tf.zeros([16000] - tf.shape(waveform), dtype=tf.float32)\n",
    "\n",
    "    # Concatenate audio with padding so that all audio clips will be of the \n",
    "    # same length\n",
    "    waveform = tf.cast(waveform, tf.float32)\n",
    "\n",
    "    equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "    equal_length = equal_length.numpy().flatten()\n",
    "    spectrogram = 30 * (\n",
    "        mel_features.log_mel_spectrogram(\n",
    "        equal_length,\n",
    "            16000,\n",
    "            log_offset=0.001,\n",
    "            window_length_secs=0.025,\n",
    "            hop_length_secs=0.010,\n",
    "            num_mel_bins=32,\n",
    "            lower_edge_hertz=60,\n",
    "            upper_edge_hertz=3800) - np.log(1e-3))\n",
    "\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-china",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:24:01.171277Z",
     "start_time": "2021-05-16T09:24:01.168899Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_spectrogram_df(X, y):\n",
    "    audios = []\n",
    "    for audio in tqdm(X):\n",
    "        spectrogram = get_spectrogram(audio)\n",
    "        audios.append(tf.expand_dims(spectrogram, -1))\n",
    "    return np.array(audios), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-essence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:27:05.229947Z",
     "start_time": "2021-05-16T09:24:02.185715Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pre, y_pre = get_spectrogram_df(X.copy(), y.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "theoretical-reach",
   "metadata": {},
   "source": [
    "### Visualize spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-gibson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:29:02.175391Z",
     "start_time": "2021-05-16T09:29:01.658057Z"
    }
   },
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 3\n",
    "n = rows*cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 8))\n",
    "for i, (audio, label) in enumerate(zip(X_pre[:9], y_pre[:9])):\n",
    "    r = i // cols\n",
    "    c = i % cols\n",
    "    ax = axes[r][c]\n",
    "    ax.imshow(audio.T[0,...,None])\n",
    "    ax.set_title(label.numpy().decode())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-array",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-march",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:30:28.391929Z",
     "start_time": "2021-05-16T09:29:08.106563Z"
    }
   },
   "outputs": [],
   "source": [
    "y_enc = np.array([labels.index(l) for l in y_pre])\n",
    "y_enc = tf.one_hot(y_enc, len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-registration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:30:28.458915Z",
     "start_time": "2021-05-16T09:30:28.456786Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-marathon",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-tumor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:31:01.426359Z",
     "start_time": "2021-05-16T09:31:01.423868Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size):\n",
    "    n_test = int(X.shape[0] * test_size)\n",
    "    X_test = X[:n_test]\n",
    "    y_test = y[:n_test]\n",
    "    X_train = X[n_test:]\n",
    "    y_train = y[n_test:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-cooper",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:31:01.759721Z",
     "start_time": "2021-05-16T09:31:01.755743Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pre, y_enc, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-highlight",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:31:02.064893Z",
     "start_time": "2021-05-16T09:31:02.062498Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-incident",
   "metadata": {},
   "source": [
    "## Standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-coupon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:31:04.396815Z",
     "start_time": "2021-05-16T09:31:04.394504Z"
    }
   },
   "outputs": [],
   "source": [
    "def standardize(X, y):\n",
    "    X -= np.mean(X, axis=1, keepdims=True)\n",
    "    X /= np.std(X, axis=1, keepdims=True)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-bhutan",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:31:07.416208Z",
     "start_time": "2021-05-16T09:31:05.548795Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_norm, y_train_norm = standardize(X_train, y_train)\n",
    "X_test_norm, y_test_norm = standardize(X_test, y_test)\n",
    "\n",
    "print(X_train_norm.shape, y_train_norm.shape)\n",
    "print(X_test_norm.shape, y_test_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-channels",
   "metadata": {},
   "source": [
    "# Build KWT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-setting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:32:16.190066Z",
     "start_time": "2021-05-16T09:32:16.186345Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.transformer import TransformerEncoder, PatchClassEmbedding\n",
    "from utils.tools import CustomSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-student",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:39:10.167560Z",
     "start_time": "2021-05-16T09:39:10.165133Z"
    }
   },
   "outputs": [],
   "source": [
    "# model configurations\n",
    "d_model = 64\n",
    "d_ff = d_model * 4\n",
    "n_heads = 1\n",
    "mlp_head_size = 256\n",
    "dropout = 0.1\n",
    "activation = tf.nn.gelu\n",
    "n_layers = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-count",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:39:10.547727Z",
     "start_time": "2021-05-16T09:39:10.544391Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_kwt(transformer, input_size):\n",
    "    # Input\n",
    "    inputs = tf.keras.layers.Input(shape=input_size)\n",
    "    \n",
    "    # Linear Projection of Flattened Patches\n",
    "    x = tf.keras.layers.Dense(d_model)(inputs)\n",
    "    \n",
    "    # Position Embedding + Extra learnable class embedding\n",
    "    x = PatchClassEmbedding(d_model, input_size[0])(x)\n",
    "    \n",
    "    # Transformer Model\n",
    "    x = transformer(x)\n",
    "    \n",
    "    # Take only the Extra Learnable Class\n",
    "    x = tf.keras.layers.Lambda(lambda x: x[:,0,:])(x)\n",
    "    \n",
    "    # MLP Head\n",
    "    x = tf.keras.layers.Dense(mlp_head_size)(x)\n",
    "    outputs = tf.keras.layers.Dense(len(labels), activation='softmax')(x)\n",
    "    \n",
    "    return tf.keras.models.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-exhibition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:39:12.214604Z",
     "start_time": "2021-05-16T09:39:10.920140Z"
    }
   },
   "outputs": [],
   "source": [
    "transformer = TransformerEncoder(d_model, n_heads, d_ff, dropout, activation, n_layers)\n",
    "model = build_kwt(transformer, input_size=X_train_norm.shape[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-absence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:39:12.337621Z",
     "start_time": "2021-05-16T09:39:12.329593Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-craft",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-canon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:39:18.978309Z",
     "start_time": "2021-05-16T09:39:18.976345Z"
    }
   },
   "outputs": [],
   "source": [
    "# set some variables\n",
    "batch_size = 64\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-overall",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:39:19.342260Z",
     "start_time": "2021-05-16T09:39:19.325699Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = CustomSchedule(d_model, warmup_steps=20000.0)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0.1),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-teach",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T09:39:23.378500Z",
     "start_time": "2021-05-16T09:39:19.718927Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train_norm, y_train_norm, \n",
    "    validation_data=(X_test_norm, y_test_norm),  \n",
    "    epochs=n_epochs, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-neutral",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T21:12:23.063047Z",
     "start_time": "2021-05-14T21:12:22.934343Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-repair",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-explorer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T21:12:56.239501Z",
     "start_time": "2021-05-14T21:12:52.445489Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-syria",
   "metadata": {},
   "source": [
    "# Convert to TensorFlow-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-cedar",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T16:35:05.457950Z",
     "start_time": "2021-05-14T16:35:05.431783Z"
    }
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-sharing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T16:35:17.080333Z",
     "start_time": "2021-05-14T16:35:06.633519Z"
    }
   },
   "outputs": [],
   "source": [
    "# start conversion\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-albuquerque",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T16:35:18.305176Z",
     "start_time": "2021-05-14T16:35:18.280605Z"
    }
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "tflite_model_file = pathlib.Path('bin/model_fp32_kwt.tflite')\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.716px",
    "left": "1462.44px",
    "right": "20px",
    "top": "120px",
    "width": "263.011px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
